{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2070587-082c-4b43-8076-9f9500819e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669cf6eb-be07-4ff5-bfe4-880cc5b43846",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 0]]\n",
    "x_data = torch.tensor(data) # create tensor from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf10393-3173-4e54-9ea1-cd5624fd2070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99689ad6-2134-4263-a06e-43e27ea6fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array) # create tensor from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "693453ce-c489-4f51-bdc5-02b457491980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fefe4421-9b9c-48f5-8892-0006ff65acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.6291, 0.4676],\n",
      "        [0.8038, 0.5808]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create tensor from another tensor\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "690f5091-d32c-412f-a092-c56ef7443cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor with random or constant values\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b13c173-0950-4440-b90d-f5595fd524a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor: \n",
      " tensor([[0.9035, 0.9537, 0.5739],\n",
      "        [0.1183, 0.8422, 0.0727]]) \n",
      "\n",
      "Ones tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49259a45-1df2-4d61-a4f3-7279cac9fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77b89418-b16f-4c16-bfa5-9dcedc30a518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ddd24-2a9c-4d5a-9abc-a0941c7de4fa",
   "metadata": {},
   "source": [
    "**By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using .to method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e7db3c8-495d-4c56-acfb-234521d82180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18fac055-c3ee-47ab-a8a0-bd9aa4d3069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46f4f3d6-d045-4953-9787-45b628d41cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# torch tensors have standard numpy like slicing and indexing\n",
    "tensor = torch.ones(4, 4)\n",
    "print('First row: ',tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "399e5802-20c9-4037-87b7-43caefd5da37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b41daaf6-319f-4d44-bbfe-8e78f3095d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af90ad-c8b0-4cab-a6ba-3b8e61f29b37",
   "metadata": {},
   "source": [
    "**PyTorch has two primitives to work with data: torch.utils.data.DataLoader and torch.utils.data.Dataset. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1588bf4e-d626-42f4-855b-98c097773993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ba85c-08e7-48f2-8e85-afaec190c573",
   "metadata": {},
   "source": [
    "**PyTorch offers domain-specific libraries such as TorchText, TorchVision, and TorchAudio, all of which include datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dc6395e-25cb-4cd0-a739-a177825f0279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012288808822631836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 26421880,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b659ee5dd3b46ddb6d9adddd79157ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011349201202392578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 29515,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9b857c05f54394b8dac0e873334932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011715412139892578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4422102,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c076d4c9a6ff42768ea236247a930ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010947227478027344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5148,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d853ec295524a07a6e27f523a5362d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "200d81d1-3640-4e84-88d5-bd135844a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "989f60b5-fb2c-47d3-b032-5f451db72ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05c019-aa1f-49cb-9872-af55e65162c8",
   "metadata": {},
   "source": [
    "**To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the GPU if available.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5662c52b-d90d-47f2-a872-46595fc47d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49635d47-37de-4392-bfbb-c28507f8651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e35f71-7c97-40a9-989d-dc6b591b1d21",
   "metadata": {},
   "source": [
    "**In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the modelâ€™s parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43dd5338-0fe9-41df-b32a-5142f351026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69763450-41f5-4a9a-adc9-a62d0a5ec34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38e83ea2-1a93-4338-9210-860390e4c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.314834  [   64/60000]\n",
      "loss: 2.300505  [ 6464/60000]\n",
      "loss: 2.276130  [12864/60000]\n",
      "loss: 2.256321  [19264/60000]\n",
      "loss: 2.248465  [25664/60000]\n",
      "loss: 2.218331  [32064/60000]\n",
      "loss: 2.222934  [38464/60000]\n",
      "loss: 2.197017  [44864/60000]\n",
      "loss: 2.180409  [51264/60000]\n",
      "loss: 2.141191  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 2.142620 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.164568  [   64/60000]\n",
      "loss: 2.155541  [ 6464/60000]\n",
      "loss: 2.089044  [12864/60000]\n",
      "loss: 2.093297  [19264/60000]\n",
      "loss: 2.053152  [25664/60000]\n",
      "loss: 1.986752  [32064/60000]\n",
      "loss: 2.011150  [38464/60000]\n",
      "loss: 1.937925  [44864/60000]\n",
      "loss: 1.931448  [51264/60000]\n",
      "loss: 1.850582  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 1.857652 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.901914  [   64/60000]\n",
      "loss: 1.873835  [ 6464/60000]\n",
      "loss: 1.747557  [12864/60000]\n",
      "loss: 1.778630  [19264/60000]\n",
      "loss: 1.672628  [25664/60000]\n",
      "loss: 1.626101  [32064/60000]\n",
      "loss: 1.640775  [38464/60000]\n",
      "loss: 1.553524  [44864/60000]\n",
      "loss: 1.570272  [51264/60000]\n",
      "loss: 1.461632  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 1.485474 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.558399  [   64/60000]\n",
      "loss: 1.525976  [ 6464/60000]\n",
      "loss: 1.373756  [12864/60000]\n",
      "loss: 1.443553  [19264/60000]\n",
      "loss: 1.316935  [25664/60000]\n",
      "loss: 1.320897  [32064/60000]\n",
      "loss: 1.336149  [38464/60000]\n",
      "loss: 1.268587  [44864/60000]\n",
      "loss: 1.298598  [51264/60000]\n",
      "loss: 1.200750  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.226534 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.303691  [   64/60000]\n",
      "loss: 1.286480  [ 6464/60000]\n",
      "loss: 1.121483  [12864/60000]\n",
      "loss: 1.230451  [19264/60000]\n",
      "loss: 1.093194  [25664/60000]\n",
      "loss: 1.125139  [32064/60000]\n",
      "loss: 1.151193  [38464/60000]\n",
      "loss: 1.092641  [44864/60000]\n",
      "loss: 1.129367  [51264/60000]\n",
      "loss: 1.044978  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.066717 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae194cb7-1bf9-4412-9280-1457089a7f88",
   "metadata": {},
   "source": [
    "**Saving Models --\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7abc4cc-edb0-4307-b88e-814a1b2c2ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e214fb-ca11-40c0-bf8a-77e01d67e87a",
   "metadata": {},
   "source": [
    "**The process for loading a model includes re-creating the model structure and loading the state dictionary into it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e605f5ac-9d62-4ffa-be50-7ed8152629c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf66c3-c158-4761-a831-501b52ab0a3b",
   "metadata": {},
   "source": [
    "**Let us use this model and make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6d57646-9034-4ff9-b954-45c381893183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67bd24-855f-4cdf-989e-6a132e2c1bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
